{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(112358)\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import resample\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# TensorFlow and tf.keras\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overall Approach\n",
    "I took a sequential approach, changing one hyperparameter at a time and seeing if changing that hyperparameter improved the model. If it did improve the model then I kept the change and tried a different adaptation. However, I took a logical order through the various hyperparameter options. I started by adjusting Adam. I realised that you must start with small numbers (coefficients) for L2 regulaization and increase them. Small numbers mean less penalisation in this instance. However, using too high values for the coefficients resulted in the penalisation reducing the ability for the model to train on the data and therefore resulted in lower scores. Therefore I used a value in between these extremes. My validation score is much higher than the test score on kaggle which may suggest that there is a lot of noise in the data and the model is fitting to that noise. Therefore, data augmentation would be useful in this instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "The Kannada MNIST dataset was used, which is a large database of handwritten digits in the indigenous language Kannada.\n",
    "\n",
    "This dataset consists of 60,000 28x28 grayscale images of the ten digits, along with a test set of 10,000 images.\n",
    "\n",
    "For this homework, we will simplify the problem by only using the digits labeled 0 and 1 owing to the similarity of the two symbols, and we will use a total of 1,200 samples for training (this includes the data you will use for validation).\n",
    "\n",
    "More details: https://arxiv.org/pdf/1908.01242.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Get Data and visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kmnist_test = pd.read_csv('/Users/phili/data/kmnist_test.csv')\n",
    "kmnist_train = pd.read_csv('/Users/phili/data/kmnist_train.csv')\n",
    "X_train = kmnist_train.drop('output', axis=1).values\n",
    "y_train = kmnist_train['output'].values\n",
    "\n",
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train = (X_train - X_train.min(axis=0)) / (X_train.max(axis=0) - X_train.min(axis=0))\n",
    "\n",
    "print(X_train.min(), X_train.max())\n",
    "\n",
    "#print(X_train.shape, y_train.shape, '\\n\\n', X_train[56][:2], '\\n\\n', set(y_train))\n",
    "\n",
    "zero_df = kmnist_train[kmnist_train['output']==0]\n",
    "zero_array = zero_df.drop('output', axis=1).values\n",
    "one_df = kmnist_train[kmnist_train['output']==1]\n",
    "one_array = one_df.drop('output', axis=1).values\n",
    "\n",
    "first_zero = zero_array[0].reshape(28,28)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(first_zero, cmap=plt.get_cmap('gray'))\n",
    "plt.xlabel('First example of a zero')\n",
    "plt.colorbar()\n",
    "\n",
    "first_one = one_array[0].reshape(28,28)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(first_one, cmap=plt.get_cmap('gray'))\n",
    "plt.xlabel('First example of a one')\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Fit initial overfit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 7\n",
    "np.random.seed(seed)\n",
    "\n",
    "X_train = X_train.reshape(-1, 28, 28,1)\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state.\n",
    "\n",
    "# your code here\n",
    "n_neurons = 100\n",
    "n_input = len(X_train[0])\n",
    "n_output = 1\n",
    "\n",
    "model_overfit = tf.keras.models.Sequential(name='Model_Overfit')\n",
    "\n",
    "model_overfit .add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "#First hidden layer\n",
    "model_overfit.add((tf.keras.layers.Dense(n_neurons,activation = 'relu')))\n",
    "\n",
    "#Second hidden layer\n",
    "model_overfit.add((tf.keras.layers.Dense(n_neurons,activation = 'relu')))\n",
    "\n",
    "#Third hidden layer\n",
    "model_overfit.add((tf.keras.layers.Dense(n_neurons,activation = 'relu')))\n",
    "\n",
    "# output layer, one neuron \n",
    "model_overfit.add(tf.keras.layers.Dense(n_output,  activation='sigmoid'))\n",
    "\n",
    "model_overfit.summary()\n",
    "\n",
    "#Do we need to reshape in order for keras to use the data properly?\n",
    "#How do we choose softmax vs linear for output and activation and optimiser/ loss functiom combo?\n",
    "\n",
    "%%time\n",
    "optimizer = optimizers.Adam(lr=0.001) #Default learning rate.\n",
    "\n",
    "model_overfit.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_overfit = model_overfit.fit(X_train,y_train, epochs = 1000, batch_size = 128,verbose=1,validation_split=0.3)\n",
    "\n",
    "#Should it be binary cross_entropy loss because we have a binary target variable? - is the target variable the response variable?\n",
    "\n",
    "# plot accuracy and loss for the test set\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(history_overfit.history['accuracy'])\n",
    "ax[0].plot(history_overfit.history['val_accuracy'])\n",
    "ax[0].set_title('Model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "ax[1].plot(history_overfit.history['loss'])\n",
    "ax[1].plot(history_overfit.history['val_loss'])\n",
    "ax[1].set_title('Model loss')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['train', 'val'], loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTERPRETATION:**\n",
    "\n",
    "You can tell that the model is overfitting because there is a discrepancy between the validation accuracy and the training accuracy. This is further shown by the fact that the learning rate immediately moves to one. This suggests that the model is finding features in the training data and learing those intensively, and may not be able to generalize as successfully to unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regularised Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TO CHANGE: epochs, L2 norm, dropout, batch size, optimizer.\n",
    "#ORDER: Adam, L1, L2, Epochs, Batch Size, Dropout.Other o\n",
    "# Adam: 0.2-0.4\n",
    "n_neurons = 100\n",
    "n_input = len(X_train[0])\n",
    "n_output = 1\n",
    "#kernel_weight = 0.005\n",
    "#bias_weight = 0.00\n",
    "#callback = callbacks.EarlyStopping(monitor='val_loss', patience=55)\n",
    "        \n",
    "#kernel_regularizer=myl1_reg\n",
    "\n",
    "myl2_reg = regularizers.l2(0.08)\n",
    "myl1_reg = regularizers.l1(0.004) \n",
    "\n",
    "model_reg = tf.keras.models.Sequential(name='Model_reg')\n",
    "\n",
    "model_reg.add(tf.keras.layers.Flatten(input_shape=(28, 28)))\n",
    "\n",
    "#First hidden layer\n",
    "model_reg.add((tf.keras.layers.Dense(n_neurons, kernel_regularizer=myl2_reg, activation = 'relu')))\n",
    "\n",
    "#Second hidden layer\n",
    "model_reg.add((tf.keras.layers.Dense(n_neurons,kernel_regularizer=myl2_reg, activation = 'relu')))\n",
    "\n",
    "#Third hidden layer\n",
    "model_reg.add((tf.keras.layers.Dense(n_neurons,kernel_regularizer=myl2_reg, activation = 'relu')))\n",
    "\n",
    "model_reg.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "# output layer, one neuron \n",
    "model_reg.add(tf.keras.layers.Dense(n_output,  activation='sigmoid'))\n",
    "\n",
    "model_reg.summary()\n",
    "\n",
    "#Do we need to reshape in order for keras to use the data properly?\n",
    "#How do we choose softmax vs linear for output and activation and optimiser/ loss functiom combo?\n",
    "\n",
    "%%time\n",
    "optimizer = optimizers.Adam(lr=0.00003)\n",
    "#optimizer = optimizers.SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "model_reg.compile(optimizer=optimizer,\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history_reg = model_reg.fit(X_train,y_train, epochs = 2000, verbose=0,batch_size = 32, validation_split=0.3)\n",
    "\n",
    "#Should it be binary cross_entropy loss because we have a binary target variable? - is the target variable the response variable?\n",
    "\n",
    "history_reg = model_reg.fit_generator(datagen_train.flow(X_train, y_train, batch_size=32),\n",
    "                              steps_per_epoch=len(X_train)//32,\n",
    "                              epochs=2000,\n",
    "                              verbose=2)\n",
    "\n",
    "print('Val accuracy in the model on the last epoch is', history_reg.history['val_accuracy'][-1])\n",
    "print('Train accuracy in the model on the last epoch is', history_reg.history['accuracy'][-1])\n",
    "print('Train loss in the model on the last epoch is', history_reg.history['loss'][-1])\n",
    "print('Val loss in the model on the last epoch is', history_reg.history['val_loss'][-1])\n",
    "\n",
    "tf.keras.backend.clear_session()  # For easy reset of notebook state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def array_exists(arr):\n",
    "        return hasattr(arr, 'shape')\n",
    "#check if the numpy array exists\n",
    "\n",
    "def reshape_if_exists(arr):\n",
    "    if array_exists(arr):\n",
    "        return arr['x'].values.reshape(-1,1), arr['y'].values.reshape(-1,1)\n",
    "    else:\n",
    "        return None, None\n",
    "    \n",
    "def reshape_and_extract_sets(train_set, test_set):\n",
    "    \"\"\"\n",
    "    Extracts x_train, y_train, x_test and y_test and reshapes them for using with keras.\n",
    "    \"\"\"    \n",
    "    x_train, y_train = reshape_if_exists(train_set)\n",
    "    x_test, y_test   = reshape_if_exists(test_set)\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "def plot_loss(model_history, rolling = None, title = \"Loss vs Epoch \"):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        model_history : the nueral network model history to plot\n",
    "        title   : if you want a title other than the default plot it.\n",
    "        rolling : this will plot a rolling average of the loss (purely for visualization purposes)\n",
    "    \"\"\"\n",
    "    plt.figure(figsize = (12,5))\n",
    "    train_loss = model_history.history['loss']\n",
    "    val_loss = model_history.history['val_loss']\n",
    "    set_colors = {\"train\": sns.color_palette()[0],\n",
    "                 \"val\": sns.color_palette()[1]}\n",
    "    \n",
    "    if rolling:\n",
    "        alphas = [0.45, 0.35]\n",
    "    else:\n",
    "        alphas = [0.8, 0.6]\n",
    "    \n",
    "    plt.loglog( train_loss, linewidth=3, label = 'Training', alpha = alphas[0], color = set_colors[\"train\"])\n",
    "    \n",
    "    plt.loglog( val_loss, linewidth=3, label = 'Validation', color = set_colors[\"val\"], alpha=alphas[1])\n",
    "    \n",
    "    if rolling:\n",
    "        plt.plot(pd.Series(train_loss).rolling(rolling).mean(),linewidth=4, \n",
    "                 label = 'Train loss rolling avg.', color = set_colors[\"train\"])\n",
    "        plt.plot(pd.Series(val_loss).rolling(rolling).mean(),linewidth=4, \n",
    "                 label = 'Val loss rolling avg.', color = set_colors[\"val\"])\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "plot_loss(history_reg, rolling = 30)\n",
    "\n",
    "# plot accuracy and loss for the test set\n",
    "fig, ax = plt.subplots(1,2, figsize=(20,6))\n",
    "\n",
    "ax[0].plot(history_reg.history['accuracy'])\n",
    "ax[0].plot(history_reg.history['val_accuracy'])\n",
    "ax[0].set_title('Model accuracy')\n",
    "ax[0].set_ylabel('accuracy')\n",
    "ax[0].set_xlabel('epoch')\n",
    "ax[0].legend(['train', 'val'], loc='best')\n",
    "\n",
    "ax[1].plot(history_reg.history['loss'])\n",
    "ax[1].plot(history_reg.history['val_loss'])\n",
    "ax[1].set_title('Model loss')\n",
    "ax[1].set_ylabel('loss')\n",
    "ax[1].set_xlabel('epoch')\n",
    "ax[1].legend(['train', 'val'], loc='best')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
